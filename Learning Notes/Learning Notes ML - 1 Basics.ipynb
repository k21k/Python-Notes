{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Machine Learning 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Some Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Mean Absolute Error (MAE) is the mean of the absolute value of the errors\n",
    "Mean Squared Error (MSE) is the mean of the squared errors:\n",
    "Root Mean Squared Error (RMSE) is the square root of the mean of the squared errors\n",
    "\n",
    "Comparing these metrics:\n",
    "\n",
    "MAE is the easiest to understand because it’s the average error.\n",
    "MSE is more popular than MAE because MSE “punishes” larger errors, which tends to be useful in the real world.\n",
    "RMSE is even more popular than MSE because RMSE is interpretable in the “y” units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# to get the metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred)) \n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred)) \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) \n",
    "\n",
    "# Different way, just for illustration\n",
    "y_pred = linreg.predict(X_test) \n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "print(MSE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Lets say that the model inputs are\n",
    "X = df[['Weight', 'Volume']]\n",
    "y = df['CO2']\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, y)\n",
    "\n",
    "# Simply do that for predicting the CO2 emission of a car where the weight is 2300kg, and the volume is 1300ccm:\n",
    "predictedCO2 = regr.predict([[2300, 1300]])\n",
    "\n",
    "print(predictedCO2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "https://docs.w3cub.com/statsmodels/generated/statsmodels.regression.linear_model.ols.fit_regularized/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "est=sm.OLS(y, X)\n",
    "est = est.fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Plotting Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# provided that y_test and y_pred have been called (example below)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# y_pred = linreg.predict(X_test)\n",
    "\n",
    "sns.distplot((y_test-y_pred),bins=50)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Interpretation of Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Almost all the real-world problems that you are going to encounter will have more than two variables. \n",
    "Linear regression involving multiple variables is called “multiple linear regression” or multivariate linear regression. \n",
    "The steps to perform multiple linear regression are almost similar to that of simple linear regression. \n",
    "\n",
    "The difference lies in the evaluation. \n",
    "You can use it to find out which factor has the highest impact on the predicted output and how different variables relate to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
