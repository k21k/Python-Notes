{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# MACHINE LEARNING 1 - BASICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# ML Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Type of tasks\n",
    "  - Classification\n",
    "  - Regression\n",
    "  - Structured annotation\n",
    "  - Clustering\n",
    "  - Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Challenges\n",
    "  - Quality of data \n",
    "  - Time-Consuming task − Another challenge faced by ML models is the consumption of time especially for data acquisition, feature extraction and retrieval. \n",
    "  - Lack of specialist persons − As ML technology is still in its infancy stage, availability of expert resources is a tough job.\n",
    "  - No clear objective for formulating business problems \n",
    "  - Issue of overfitting & underfitting \n",
    "  - Curse of dimensionality − Another challenge ML model faces is too many features of data points. This can be a real hindrance.\n",
    "  - Difficulty in deployment − Complexity of the ML model makes it quite difficult to be deployed in real life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Applications\n",
    "  - Emotion analysis\n",
    "  - Sentiment analysis\n",
    "  - Error detection and prevention\n",
    "  - Weather forecasting and prediction\n",
    "  - Stock market analysis and forecasting\n",
    "  - Speech synthesis\n",
    "  - Speech recognition\n",
    "  - Customer segmentation\n",
    "  - Object recognition\n",
    "  - Fraud detection\n",
    "  - Fraud prevention\n",
    "  - Recommendation of products to customer in online shopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# Categorisation of the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Categorize by input:\n",
    "- If you have labelled data, it’s a supervised learning problem.\n",
    "- If you have unlabelled data and want to find structure, it’s an unsupervised learning problem.\n",
    "- If you want to optimize an objective function by interacting with an environment, it’s a reinforcement learning problem.\n",
    "\n",
    "Categorize by output.\n",
    "- If the output of your model is a number, it’s a regression problem.\n",
    "- If the output of your model is a class, it’s a classification problem.\n",
    "- If the output of your model is a set of input groups, it’s a clustering problem.\n",
    "- Do you want to detect an anomaly ? That’s anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# Learning Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "- The majority of practical machine learning uses supervised learning.\n",
    "- Supervised learning is where you have input variables (x) and an output variable (Y) and you use an algorithm to learn the mapping function from the input to the output.\n",
    "- Y = f(X)\n",
    "- It is called supervised learning because the process of an algorithm learning from the training dataset can be thought of as a teacher supervising the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Supervised learning problems can be further grouped into regression and classification problems.\n",
    "  - Classification: A classification problem is when the output variable is a category, such as “red” or “blue” or “disease” and “no disease”.\n",
    "  - Regression: A regression problem is when the output variable is a real value, such as “dollars” or “weight”.\n",
    "\n",
    "Some common types of problems built on top of classification and regression include recommendation and time series prediction respectively.\n",
    "\n",
    "Some popular examples of supervised machine learning algorithms are:\n",
    "  - Linear regression for regression problems.\n",
    "  - Random forest for classification and regression problems.\n",
    "  - Support vector machines for classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Unsupervised learning is where you only have input data (X) and no corresponding output variables.\n",
    "The goal for unsupervised learning is to model the underlying structure or distribution in the data in order to learn more about the data.\n",
    "\n",
    "These are called unsupervised learning because unlike supervised learning above there is no correct answers and there is no teacher. \n",
    "Algorithms are left to their own devises to discover and present the interesting structure in the data.\n",
    "\n",
    "Unsupervised learning problems can be further grouped into clustering and association problems.\n",
    "  - Clustering: A clustering problem is where you want to discover the inherent groupings in the data, such as grouping customers by purchasing behavior.\n",
    "  - Association:  An association rule learning problem is where you want to discover rules that describe large portions of your data, such as people that buy X also tend to buy Y.\n",
    "\n",
    "Some popular examples of unsupervised learning algorithms are:\n",
    "  - k-means for clustering problems.\n",
    "  - Apriori algorithm for association rule learning problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Semi Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Problems where you have a large amount of input data (X) and only SOME of the data is labeled (Y) are called semi-supervised learning problems.\n",
    "\n",
    "These problems sit in between both supervised and unsupervised learning.\n",
    "  - A good example is a photo archive where only some of the images are labeled, (e.g. dog, cat, person) and the majority are unlabeled.\n",
    "  - Many real world machine learning problems fall into this area.\n",
    "  - This is because it can be expensive or time-consuming to label data as it may require access to domain experts. Whereas unlabeled data is cheap and easy to collect and store.\n",
    "\n",
    "You can use unsupervised learning techniques to discover and learn the structure in the input variables.\n",
    "You can also use supervised learning techniques to make best guess predictions for the unlabeled data, feed that data back into the supervised learning algorithm as training data and use the model to make predictions on new unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Basic Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept    14.952480\n",
      "B             0.401182\n",
      "C             0.000352\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as sm\n",
    "df = pd.DataFrame({\"A\": [10,20,30,40,50], \"B\": [20, 30, 10, 40, 50], \"C\": [32, 234, 23, 23, 42523]})\n",
    "result = sm.ols(formula=\"A ~ B + C\", data=df).fit()\n",
    "print(result.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      A   R-squared:                       0.579\n",
      "Model:                            OLS   Adj. R-squared:                  0.158\n",
      "Method:                 Least Squares   F-statistic:                     1.375\n",
      "Date:                Tue, 16 Jun 2020   Prob (F-statistic):              0.421\n",
      "Time:                        10:44:00   Log-Likelihood:                -18.178\n",
      "No. Observations:                   5   AIC:                             42.36\n",
      "Df Residuals:                       2   BIC:                             41.19\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     14.9525     17.764      0.842      0.489     -61.481      91.386\n",
      "B              0.4012      0.650      0.617      0.600      -2.394       3.197\n",
      "C              0.0004      0.001      0.650      0.583      -0.002       0.003\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   1.061\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.498\n",
      "Skew:                          -0.123   Prob(JB):                        0.780\n",
      "Kurtosis:                       1.474   Cond. No.                     5.21e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.21e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delchain_default\\anaconda3\\lib\\site-packages\\statsmodels\\stats\\stattools.py:71: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n",
      "  \"samples were given.\" % int(n), ValueWarning)\n"
     ]
    }
   ],
   "source": [
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Interpretation of a regression Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "R-squared        - coeff of determination. How well the regression line approximates real data points\n",
    "Adj. R-squared   - same as above, adjsuted for number of observations and degrees of freedom of residuals\n",
    "F-Stat           - measure of how significant the fit is. Mean sq error / mean sq error of residuals\n",
    "Prob(F-stat)     - prob to get F-stat, given the null hypothesis they are unrelated\n",
    "Log-Likelihood   - value of the likelihood function of the fitted model\n",
    "AIC              - Akaike Information Criterion: adjusts log-likelihood based on number of observations and complexity of model   \n",
    "BIC              - Bayesian Information Criterion: same as AIC, but with higher penalty for models wit more parameters\n",
    "Df Residuals     - degrees of freedom of the residulas. Number of observations - number of parameters\n",
    "Df Model         - number of parameters in the model (not including the constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Coef             - estimated value of coeff\n",
    "Std err          - basic standard error of the estimate of coeff. \n",
    "t                - t-stat (how statistically significant the coeff is)\n",
    "P>|t|            - p-value that null hypothesis that the coeff = 0 is true. if < 0.05: strong relationship between term and response\n",
    "95% Conf.Int     - lower and upper value of the 95% confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Omnibus          - Angostino test: provides a combined statistical test of the presence of skewness and kurtosis\n",
    "Prob(Omnibus)    - same as above, turned into prob\n",
    "Skew             - measure of symmetry of data around mean\n",
    "Kurtosis         - measure of shape distribution\n",
    "Durbin-Watson    - test for autocorrelation (important in time series)\n",
    "Jarque=Bera      - different test of skewness and kurtosis\n",
    "Prob (JB)\n",
    "Cond.No          - test for multicolinearity (parameters are related to each other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Log Likelihood\n",
    "  - not possible to compare raw log-lieklihoods between models (better to use AIC or BIC)\n",
    "  - Likelihood is the likelihood of the entire model given a set of parameter estimates.\n",
    "  - It is calculated by \n",
    "    - taking a set of parameter estimates\n",
    "    - calculating the probability density for each one\n",
    "    - multiplying the probability densities for all the observations together \n",
    "    - >> this follows from probability theory in that P(A and B) = P(A)P(B) if A and B are independent)\n",
    "  - In practice, what this means for linear regression:\n",
    "    - you take a set of parameter estimates (beta, sd)\n",
    "    - plug them into the normal pdf\n",
    "    - calculate the density for each observation y at that set of parameter estimates\n",
    "    - multiply them all together. \n",
    "  - Typically, we choose to work with the log-likelihood because \n",
    "    - it is easier to calculate because instead of multiplying we can sum (log(a*b) = log(a) + log(b)), which is computationally faster. \n",
    "\n",
    "Log likelihood is used for almost everything. \n",
    "  - It is the basic quantity that we use to find parameter estimates (Maximum Likelihood Estimates) for a huge suite of models. \n",
    "  - For simple linear regression, these estimates turn out to be the same as those for least squares, but for more complicated models least squares may not work.\n",
    "\n",
    "AIC\n",
    "  - Lower value of AIC suggests \"better\" model, but it is a relative measure of model fit \n",
    "  - It is used for model selection (only), i.e. it lets you to compare different models estimated on the same dataset\n",
    "  - Lower indicates a more parsimonious model, relative to a model fit with a higher AIC.\n",
    "  - Model selection conducted with the AIC will choose the same model as leave-one-out cross validation \n",
    "  - Dont compare too many models with the AIC (like with p-values) because lowest AIC does not mean that it is the most appropriate mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Omnibus          \n",
    "  - We want something close to zero, which means normalcy of residuals\n",
    "        \n",
    "Prob(Omnibus)    \n",
    "  - statistical test that residuals are normally distributed\n",
    "  - we want something close to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Skew\n",
    "  - closer to 0 means symetric residual distribution\n",
    "  - If skewness is less than −1 or greater than +1, the distribution is highly skewed.\n",
    "  - If skewness is between −1 and −½ or between +½ and +1, the distribution is moderately skewed.\n",
    "  - If skewness is between −½ and +½, the distribution is approximately symmetric.\n",
    "    \n",
    "Kurtosis\n",
    "  - a uniform distribution has a kurtosis of 1.8 (excess -1.2) (lowest is discrete with 2 outcomes: kurto 1)\n",
    "  - a normal distribution has a kurtosis of 3 (excess 0)\n",
    "  - a logistic distribution has a kurtosis of 4.2 (excess 1.2)\n",
    "  - highest kurtosis is a student distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Durbin-Watson\n",
    "  - Value between zero and 4.0\n",
    "  - we hope to get a value between 1 and 2. ideally 2\n",
    "  - A value of 2.0 means there is no autocorrelation detected in the sample. \n",
    "  - values from zero to 2.0 indicate positive autocorrelation\n",
    "  - values from 2.0 to 4.0 indicate negative autocorrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Condition Number \n",
    "  – This test measures the sensitivity of a function output as compared to its input.\n",
    "  - When we have multicollinearity, we can expect much higher fluctuations to small changes in the data\n",
    "  - We want a relatively small number (something below 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Train Accuracy vs Test Accuracy vs Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Accuracy: \n",
    "  - The amount of correct classifications / the total amount of classifications.\n",
    "  - The train accuracy: The accuracy of a model on examples it was constructed on.\n",
    "  - The test accuracy is the accuracy of a model on examples it hasn't seen.\n",
    "\n",
    "Confusion matrix: \n",
    "  - Confusion matrix returns the testing accuracy \n",
    "  - A tabulation of the predicted class (usually vertically) against the actual class (thus horizontally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Confusion matrix \n",
    "  - matrix (table) that can be used to measure the performance of an machine learning algorithm, usually a supervised learning one\n",
    "\n",
    "By convention here\n",
    "  - row = instances of an actual class \n",
    "  - column = instances of a predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# 2 Class looks like this\n",
    "-----------------------------------------------------------------\n",
    "                    Predicted Negative      Predicted Positive\n",
    "Actual Negative       True Negative            False Positive\n",
    "Actual Positive       False NEgative           True Positive\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Accuracy = (TN + TP) / (Total)\n",
    "Precision = TP / (FP + TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Implementation in Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cm = np.array(\n",
    "[[5825,    1,   49,   23,    7,   46,   30,   12,   21,   26],\n",
    " [   1, 6654,   48,   25,   10,   32,   19,   62,  111,   10],\n",
    " [   2,   20, 5561,   69,   13,   10,    2,   45,   18,    2],\n",
    " [   6,   26,   99, 5786,    5,  111,    1,   41,  110,   79],\n",
    " [   4,   10,   43,    6, 5533,   32,   11,   53,   34,   79],\n",
    " [   3,    1,    2,   56,    0, 4954,   23,    0,   12,    5],\n",
    " [  31,    4,   42,   22,   45,  103, 5806,    3,   34,    3],\n",
    " [   0,    4,   30,   29,    5,    6,    0, 5817,    2,   28],\n",
    " [  35,    6,   63,   58,    8,   59,   26,   13, 5394,   24],\n",
    " [  16,   16,   21,   57,  216,   68,    0,  219,  115, 5693]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def precision(label, confusion_matrix):\n",
    "    col = confusion_matrix[:, label]\n",
    "    return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "def recall(label, confusion_matrix):\n",
    "    row = confusion_matrix[label, :]\n",
    "    return confusion_matrix[label, label] / row.sum()\n",
    "\n",
    "def precision_macro_average(confusion_matrix):\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_precisions = 0\n",
    "    for label in range(rows):\n",
    "        sum_of_precisions += precision(label, confusion_matrix)\n",
    "    return sum_of_precisions / rows\n",
    "\n",
    "def recall_macro_average(confusion_matrix):\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_recalls = 0\n",
    "    for label in range(columns):\n",
    "        sum_of_recalls += recall(label, confusion_matrix)\n",
    "    return sum_of_recalls / columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label precision recall\n",
      "    0     0.983  0.964\n",
      "    1     0.987  0.954\n",
      "    2     0.933  0.968\n",
      "    3     0.944  0.924\n",
      "    4     0.947  0.953\n",
      "    5     0.914  0.980\n",
      "    6     0.981  0.953\n",
      "    7     0.928  0.982\n",
      "    8     0.922  0.949\n",
      "    9     0.957  0.887\n"
     ]
    }
   ],
   "source": [
    "print(\"label precision recall\")\n",
    "for label in range(10):\n",
    "    print(f\"{label:5d} {precision(label, cm):9.3f} {recall(label, cm):6.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision total: 0.9496885564052286\n",
      "recall total: 0.9514531547877969\n"
     ]
    }
   ],
   "source": [
    "print(\"precision total:\", precision_macro_average(cm))\n",
    "print(\"recall total:\", recall_macro_average(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Implementation in Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 0],\n",
       "       [0, 1, 2],\n",
       "       [2, 1, 3]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_actu = [2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 1, 2]\n",
    "y_pred = [0, 0, 2, 1, 0, 2, 1, 0, 2, 0, 2, 2]\n",
    "\n",
    "confusion_matrix(y_actu, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5833333333333334"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_actu, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Models Adequacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Good Article\n",
    "https://www.hackernoon.com/choosing-the-right-machine-learning-algorithm-68126944ce1f\n",
    "    \n",
    "# Good Cheatsheet \n",
    "http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Classification is the task of predicting the type or class of an object within a finite number of options. \n",
    "The output variable for classification is always a categorical variable. \n",
    "\n",
    "- K-Nearest neighbors algorithm – simple but computationally exhaustive.\n",
    "- Naive Bayes – Based on Bayes theorem.\n",
    "- Logistic Regression – Linear model for binary classification.\n",
    "- SVM – can be used for binary/multiclass classifications.\n",
    "- Decision Tree – ‘If Else’ based classifier, more robust to outliers.\n",
    "- Ensembles – Combination of multiple machine learning models clubbed together to get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Regression is a set of problems where the output variable can take continuous values\n",
    "\n",
    "- Linear Regression – Simplest baseline model for regression task, works well only when data is linearly separable and very less or no multicollinearity is present.\n",
    "- Lasso Regression – Linear regression with L2 regularization.\n",
    "- Ridge Regression – Linear regression with L1 regularization.\n",
    "- SVM regression\n",
    "- Decision Tree Regression etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Clustering is the task of grouping similar objects together. \n",
    "Machine learning models help to identify similar objects automatically without manual intervention. \n",
    "We can not build effective supervised machine learning models (models that need to be trained with manually curated or labeled data) without homogeneous data.\n",
    "\n",
    "- K means – Simple but suffers from high variance.\n",
    "- K means++ – Modified version of K means.\n",
    "- K medoids.\n",
    "- Agglomerative clustering – A hierarchical clustering model.\n",
    "- DBSCAN – Density-based clustering algorithm etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Dimensionality is the number of predictor variables used to predict the independent variable or target.\n",
    "Often in the real world datasets the number of variables is too high. \n",
    "Too many variables also bring the curse of overfitting to the models.\n",
    "In practice among these large numbers of variables, not all variables contribute equally towards the goal.\n",
    "In a large number of cases, we can actually preserve variances with a lesser number of variables\n",
    "\n",
    "- PCA – It creates lesser numbers of new variables out of a large number of predictors. The new variables are independent of each other but less interpretable.\n",
    "- TSNE – Provides lower dimensional embedding of higher-dimensional data points.\n",
    "- SVD – Singular value decomposition is used to decompose the matrix into smaller parts in order to efficient calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Deep learning is a subset of machine learning which deals with neural networks. \n",
    "Based on the architecture of neural networks let’s list down important deep learning models:\n",
    "- Multi-Layer perceptron\n",
    "- Convolution Neural Networks\n",
    "- Recurrent Neural Networks\n",
    "- Boltzmann machine\n",
    "- Autoencoders etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "There is always a need to validate the stability of the machine learning model and need some kind of assurance that:\n",
    "  - the  model has got most of the patterns from the data correct\n",
    "  - the model is not picking up too much on the noise\n",
    "  - the model is low on bias and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Validation\n",
    "  - process of deciding whether the numerical results quantifying hypothesized relationships between variables, are acceptable as descriptions of the data.\n",
    "\n",
    "Residiuals\n",
    "  - evaluation of residuals = error estimation for the model is made after training \n",
    "  - a numerical estimate of the difference in predicted and original responses is done, also called the training error. \n",
    "  - However, this only gives us an idea about how well our model does on the data used to train it. \n",
    "  - It possible that the model is underfitting or overfitting the data. \n",
    "\n",
    "Cross Validation:\n",
    "  - Pupose: get an indication of how well the learner will generalize to an independent / unseen data set\n",
    "  - How: discussed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Model Bias / Variance\n",
    "\n",
    "Bias\n",
    "  - In an ideal scenario, these error values should sum up to zero. \n",
    "  - To return the model’s bias, we take the average of all the errors. \n",
    "  - The lower the average value, better the model.\n",
    "\n",
    "Variance\n",
    "  - Similarly for calculating the model variance, we take standard deviation of all the errors. \n",
    "  - A low value of standard deviation suggests our model does not vary a lot with different subsets of training data.\n",
    "\n",
    "We should focus on achieving a balance between bias and variance. \n",
    "  - This can be done by reducing the variance and controlling bias to an extent.\n",
    "  - This will result in a better predictive model.\n",
    "  - This trade-off usually leads to building less complex predictive models as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "The Problem\n",
    "  - As there is never enough data to train your model, removing a part of it for validation poses a problem of underfitting. \n",
    "  - By reducing the training data, we risk losing important patterns/ trends in data set, which in turn increases error induced by bias. \n",
    "\n",
    "The Solution\n",
    "  - What we require is a method that provides ample data for training the model and also leaves ample data for validation. \n",
    "  - K-Fold cross validation does exactly that.\n",
    "\n",
    "K Fold cross validation\n",
    "  - the data is divided into k subsets. \n",
    "  - the holdout method is repeated k times, such that each time:\n",
    "      - one of the k subsets is used as the test set / validation set\n",
    "      - the other k-1 subsets are put together to form a training set. \n",
    "  - The error estimation is averaged over all k trials to get total effectiveness of our model. \n",
    "  - As can be seen, every data point gets to be in a validation set exactly once, and gets to be in a training set k-1 times. \n",
    "  - This significantly reduces\n",
    "      - bias as we are using most of the data for fitting\n",
    "      - variance as most of the data is also being used in validation set. \n",
    "  - Interchanging the training and test sets also adds to the effectiveness of this method. \n",
    "  - As a general rule and empirical evidence, K = 5 or 10 is generally preferred, but nothing’s fixed and it can take any value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Example of 5 Fold Cross Validation\n",
    "\n",
    "Validation  XXXXXXXXXX  XXXXXXXXXX  XXXXXXXXXX  XXXXXXXXXX\n",
    "XXXXXXXXXX  Validation  XXXXXXXXXX  XXXXXXXXXX  XXXXXXXXXX \n",
    "XXXXXXXXXX  XXXXXXXXXX  Validation  XXXXXXXXXX  XXXXXXXXXX \n",
    "XXXXXXXXXX  XXXXXXXXXX  XXXXXXXXXX  Validation  XXXXXXXXXX \n",
    "XXXXXXXXXX  XXXXXXXXXX  XXXXXXXXXX  XXXXXXXXXX  Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Stratified K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "In some cases, there may be a large imbalance in the response variables. \n",
    "  - For example, in dataset concerning price of houses, there might be large number of houses having high price. \n",
    "  - Or in case of classification, there might be several times more negative samples than positive samples. \n",
    "\n",
    "For such problems, a slight variation in the K-Fold cross validation technique is made:\n",
    "  - Each fold contains approximately the same percentage of samples of each target class as the complete set\n",
    "  - in case of prediction problems, the mean response value is approximately equal in all the folds. \n",
    "\n",
    "This variation is also known as Stratified K Fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Leave P-Out Cross Validation (exhaustive method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Exhaustive Methods computes all possible ways the data can be split into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Leave P-Out\n",
    "  - Leaves p data points out of training data\n",
    "  - Meaning: \n",
    "      - if there are n data points in the original sample then, n-p samples are used to train the model and p points are used as the validation set. \n",
    "      - This is repeated for all combinations in which original sample can be separated this way\n",
    "      - Then the error is averaged for all trials, to give overall effectiveness.\n",
    "\n",
    "This method is exhaustive in the sense that:\n",
    "  - it needs to train and validate the model for all possible combinations\n",
    "  - for moderately large p, it can become computationally infeasible.\n",
    "    \n",
    "A particular case of this method is when p = 1. \n",
    "  - This is known as Leave one out cross validation. \n",
    "  - This method is generally preferred over the previous one because it does not suffer from the intensive computation\n",
    "  - Number of possible combinations is equal to number of data points in original sample or n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "                               \n",
    "# K-Fold\n",
    "from sklearn import model_selection\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=100)                                    # chose the number of folds\n",
    "model_kfold = LinearRegression()                                                                # chose the model\n",
    "results_kfold = model_selection.cross_val_score(model_kfold, X_test, y_test, cv=kfold)\n",
    "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0))\n",
    "print(results_kfold)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Stratified k-fold cross validation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=None)\n",
    "\n",
    "# X is the feature set and y is the target\n",
    "for train_index, test_index in skf.split(X,y): \n",
    "    print(\"Train:\", train_index, \"Validation:\", val_index) \n",
    "    X_train, X_test = X[train_index], X[val_index] \n",
    "    y_train, y_test = y[train_index], y[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# k-fold cross validation with repetition (if the train set does not adequately represent the entire population, strtified is not good)\n",
    "# In repeated cross-validation, the cross-validation procedure is repeated n times, yielding n random partitions of the original sample\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "\n",
    "# X is the feature set and y is the target\n",
    "for train_index, test_index in rkf.split(X):\n",
    "     print(\"Train:\", train_index, \"Validation:\", val_index)\n",
    "     X_train, X_test = X[train_index], X[val_index]\n",
    "     y_train, y_test = y[train_index], y[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.34557351  0.34848715  0.26654262 -0.01126674  0.24875619  0.08731544\n",
      "  0.13386583  0.14000888  0.2873109   0.00960079]\n"
     ]
    }
   ],
   "source": [
    "# Using Cross Val SCore\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data[:150]\n",
    "y = diabetes.target[:150]\n",
    "lasso = linear_model.Lasso()\n",
    "print(cross_val_score(lasso, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
