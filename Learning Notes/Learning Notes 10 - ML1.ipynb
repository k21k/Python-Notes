{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Machine Learning 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Some Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## ML Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Type of tasks\n",
    "  - Classification\n",
    "  - Regression\n",
    "  - Structured annotation\n",
    "  - Clustering\n",
    "  - Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Challenges\n",
    "  - Quality of data \n",
    "  - Time-Consuming task − Another challenge faced by ML models is the consumption of time especially for data acquisition, feature extraction and retrieval. \n",
    "  - Lack of specialist persons − As ML technology is still in its infancy stage, availability of expert resources is a tough job.\n",
    "  - No clear objective for formulating business problems \n",
    "  - Issue of overfitting & underfitting \n",
    "  - Curse of dimensionality − Another challenge ML model faces is too many features of data points. This can be a real hindrance.\n",
    "  - Difficulty in deployment − Complexity of the ML model makes it quite difficult to be deployed in real life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Applications\n",
    "  - Emotion analysis\n",
    "  - Sentiment analysis\n",
    "  - Error detection and prevention\n",
    "  - Weather forecasting and prediction\n",
    "  - Stock market analysis and forecasting\n",
    "  - Speech synthesis\n",
    "  - Speech recognition\n",
    "  - Customer segmentation\n",
    "  - Object recognition\n",
    "  - Fraud detection\n",
    "  - Fraud prevention\n",
    "  - Recommendation of products to customer in online shopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept    14.952480\n",
      "B             0.401182\n",
      "C             0.000352\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as sm\n",
    "df = pd.DataFrame({\"A\": [10,20,30,40,50], \"B\": [20, 30, 10, 40, 50], \"C\": [32, 234, 23, 23, 42523]})\n",
    "result = sm.ols(formula=\"A ~ B + C\", data=df).fit()\n",
    "print(result.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      A   R-squared:                       0.579\n",
      "Model:                            OLS   Adj. R-squared:                  0.158\n",
      "Method:                 Least Squares   F-statistic:                     1.375\n",
      "Date:                Sun, 07 Jun 2020   Prob (F-statistic):              0.421\n",
      "Time:                        18:23:25   Log-Likelihood:                -18.178\n",
      "No. Observations:                   5   AIC:                             42.36\n",
      "Df Residuals:                       2   BIC:                             41.19\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     14.9525     17.764      0.842      0.489     -61.481      91.386\n",
      "B              0.4012      0.650      0.617      0.600      -2.394       3.197\n",
      "C              0.0004      0.001      0.650      0.583      -0.002       0.003\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   1.061\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.498\n",
      "Skew:                          -0.123   Prob(JB):                        0.780\n",
      "Kurtosis:                       1.474   Cond. No.                     5.21e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.21e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delchain_default\\anaconda3\\lib\\site-packages\\statsmodels\\stats\\stattools.py:71: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n",
      "  \"samples were given.\" % int(n), ValueWarning)\n"
     ]
    }
   ],
   "source": [
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Type of Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "- The majority of practical machine learning uses supervised learning.\n",
    "- Supervised learning is where you have input variables (x) and an output variable (Y) and you use an algorithm to learn the mapping function from the input to the output.\n",
    "- Y = f(X)\n",
    "- It is called supervised learning because the process of an algorithm learning from the training dataset can be thought of as a teacher supervising the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Supervised learning problems can be further grouped into regression and classification problems.\n",
    "  - Classification: A classification problem is when the output variable is a category, such as “red” or “blue” or “disease” and “no disease”.\n",
    "  - Regression: A regression problem is when the output variable is a real value, such as “dollars” or “weight”.\n",
    "\n",
    "Some common types of problems built on top of classification and regression include recommendation and time series prediction respectively.\n",
    "\n",
    "Some popular examples of supervised machine learning algorithms are:\n",
    "  - Linear regression for regression problems.\n",
    "  - Random forest for classification and regression problems.\n",
    "  - Support vector machines for classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Unsupervised learning is where you only have input data (X) and no corresponding output variables.\n",
    "The goal for unsupervised learning is to model the underlying structure or distribution in the data in order to learn more about the data.\n",
    "\n",
    "These are called unsupervised learning because unlike supervised learning above there is no correct answers and there is no teacher. \n",
    "Algorithms are left to their own devises to discover and present the interesting structure in the data.\n",
    "\n",
    "Unsupervised learning problems can be further grouped into clustering and association problems.\n",
    "  - Clustering: A clustering problem is where you want to discover the inherent groupings in the data, such as grouping customers by purchasing behavior.\n",
    "  - Association:  An association rule learning problem is where you want to discover rules that describe large portions of your data, such as people that buy X also tend to buy Y.\n",
    "\n",
    "Some popular examples of unsupervised learning algorithms are:\n",
    "  - k-means for clustering problems.\n",
    "  - Apriori algorithm for association rule learning problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Semi Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Problems where you have a large amount of input data (X) and only SOME of the data is labeled (Y) are called semi-supervised learning problems.\n",
    "\n",
    "These problems sit in between both supervised and unsupervised learning.\n",
    "  - A good example is a photo archive where only some of the images are labeled, (e.g. dog, cat, person) and the majority are unlabeled.\n",
    "  - Many real world machine learning problems fall into this area.\n",
    "  - This is because it can be expensive or time-consuming to label data as it may require access to domain experts. Whereas unlabeled data is cheap and easy to collect and store.\n",
    "\n",
    "You can use unsupervised learning techniques to discover and learn the structure in the input variables.\n",
    "You can also use supervised learning techniques to make best guess predictions for the unlabeled data, feed that data back into the supervised learning algorithm as training data and use the model to make predictions on new unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Machine Learning vs Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Deep learning is machine learning.\n",
    "  - More specifically, deep learning is considered an evolution of machine learning. \n",
    "  - It uses a programmable neural network that enables machines to make accurate decisions without help from humans.\n",
    "\n",
    "However, its capabilities are different.\n",
    "  - While basic machine learning models do become progressively better at whatever their function is, they still need some guidance. \n",
    "  - If an AI algorithm returns an inaccurate prediction, then an engineer has to step in and make adjustments. \n",
    "  - With a deep learning model, an algorithm can determine on its own if a prediction is accurate or not through its own neural network.\n",
    "    \n",
    "A deep learning model is designed to continually analyze data with a logic structure similar to how a human would draw conclusions. \n",
    "  - To achieve this, deep learning applications use a layered structure of algorithms called an artificial neural network. \n",
    "  - The design of an artificial neural network is inspired by the biological neural network of the human brain, leading to a process of learning that’s far more capable than that of standard machine learning models.\n",
    "\n",
    "It’s a tricky prospect to ensure that a deep learning model doesn’t draw incorrect conclusions—like other examples of AI, it requires lots of training to get the learning processes correct. \n",
    "But when it works as it’s intended to, functional deep learning is often received as a scientific marvel that many consider being the backbone of true artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Simple Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Importing the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### The basics in Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Declare the X and y\n",
    "X = df[['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms','Avg. Area Number of Bedrooms','Area Population']]\n",
    "y = df['Price']\n",
    "\n",
    "# Prepare the test / train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Get the sets size\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "# print the intercept and coefficients\n",
    "print(linreg.intercept_)\n",
    "print(linreg.coef_)\n",
    "\n",
    "#printing the output and coefficients\n",
    "coeff_df = pd.DataFrame(linreg.coef_,X.columns,columns=['Coefficient']) \n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Visualisation of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Plotting the predictions vs the test set\n",
    "y_pred = lm.predict(X_test)  \n",
    "plt.scatter(y_test,y_pred)\n",
    "\n",
    "# Plotting the errors\n",
    "sns.distplot((y_test-y_pred]),bins=50); \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Mean Absolute Error (MAE) is the mean of the absolute value of the errors\n",
    "Mean Squared Error (MSE) is the mean of the squared errors:\n",
    "Root Mean Squared Error (RMSE) is the square root of the mean of the squared errors\n",
    "\n",
    "Comparing these metrics:\n",
    "\n",
    "MAE is the easiest to understand because it’s the average error.\n",
    "MSE is more popular than MAE because MSE “punishes” larger errors, which tends to be useful in the real world.\n",
    "RMSE is even more popular than MSE because RMSE is interpretable in the “y” units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# to get the metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred)) \n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred)) \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Lets say that the model inputs are\n",
    "X = df[['Weight', 'Volume']]\n",
    "y = df['CO2']\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, y)\n",
    "\n",
    "# Simply do that for predicting the CO2 emission of a car where the weight is 2300kg, and the volume is 1300ccm:\n",
    "predictedCO2 = regr.predict([[2300, 1300]])\n",
    "\n",
    "print(predictedCO2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "https://docs.w3cub.com/statsmodels/generated/statsmodels.regression.linear_model.ols.fit_regularized/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "est=sm.OLS(y, X)\n",
    "est = est.fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Model Validation and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "There is always a need to validate the stability of the machine learning model and need some kind of assurance that:\n",
    "  - the  model has got most of the patterns from the data correct\n",
    "  - the model is not picking up too much on the noise\n",
    "  - the model is low on bias and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Validation\n",
    "  - process of deciding whether the numerical results quantifying hypothesized relationships between variables, are acceptable as descriptions of the data.\n",
    "\n",
    "Residiuals\n",
    "  - evaluation of residuals = error estimation for the model is made after training \n",
    "  - a numerical estimate of the difference in predicted and original responses is done, also called the training error. \n",
    "  - However, this only gives us an idea about how well our model does on the data used to train it. \n",
    "  - It possible that the model is underfitting or overfitting the data. \n",
    "\n",
    "Cross Validation:\n",
    "  - Pupose: get an indication of how well the learner will generalize to an independent / unseen data set\n",
    "  - How: discussed below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Hold Out Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Simple\n",
    "  - Removing a part of the training data and using it to get predictions from the model trained on rest of the data. \n",
    "  - The error estimation then tells how our model is doing on unseen data or the validation set. \n",
    "\n",
    "However\n",
    "  - suffers from issues of high variance since It is not certain which data points will end up in the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "The Problem\n",
    "  - As there is never enough data to train your model, removing a part of it for validation poses a problem of underfitting. \n",
    "  - By reducing the training data, we risk losing important patterns/ trends in data set, which in turn increases error induced by bias. \n",
    "\n",
    "The Solution\n",
    "  - What we require is a method that provides ample data for training the model and also leaves ample data for validation. \n",
    "  - K-Fold cross validation does exactly that.\n",
    "\n",
    "K Fold cross validation\n",
    "  - the data is divided into k subsets. \n",
    "  - the holdout method is repeated k times, such that each time:\n",
    "      - one of the k subsets is used as the test set / validation set\n",
    "      - the other k-1 subsets are put together to form a training set. \n",
    "  - The error estimation is averaged over all k trials to get total effectiveness of our model. \n",
    "  - As can be seen, every data point gets to be in a validation set exactly once, and gets to be in a training set k-1 times. \n",
    "  - This significantly reduces\n",
    "      - bias as we are using most of the data for fitting\n",
    "      - variance as most of the data is also being used in validation set. \n",
    "  - Interchanging the training and test sets also adds to the effectiveness of this method. \n",
    "  - As a general rule and empirical evidence, K = 5 or 10 is generally preferred, but nothing’s fixed and it can take any value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Stratified K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "In some cases, there may be a large imbalance in the response variables. \n",
    "  - For example, in dataset concerning price of houses, there might be large number of houses having high price. \n",
    "  - Or in case of classification, there might be several times more negative samples than positive samples. \n",
    "\n",
    "For such problems, a slight variation in the K-Fold cross validation technique is made:\n",
    "  - Each fold contains approximately the same percentage of samples of each target class as the complete set\n",
    "  - in case of prediction problems, the mean response value is approximately equal in all the folds. \n",
    "\n",
    "This variation is also known as Stratified K Fold.\n",
    "\n",
    "Above explained validation techniques are also referred to as Non-exhaustive cross validation methods. \n",
    "These do not compute all ways of splitting the original sample, i.e. you just have to decide how many subsets need to be made.\n",
    "Also, these are approximations of method explained below, also called Exhaustive Methods, that computes all possible ways the data can be split into training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Leave-P-Out Cross Validation (exchaustive method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Exhaustive Methods computes all possible ways the data can be split into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Confusion Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Interpretation of the Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Almost all the real-world problems that you are going to encounter will have more than two variables. \n",
    "Linear regression involving multiple variables is called “multiple linear regression” or multivariate linear regression. \n",
    "The steps to perform multiple linear regression are almost similar to that of simple linear regression. \n",
    "\n",
    "The difference lies in the evaluation. \n",
    "You can use it to find out which factor has the highest impact on the predicted output and how different variables relate to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
