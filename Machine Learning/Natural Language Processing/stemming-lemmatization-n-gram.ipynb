{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Devotion_Reviews.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinese people didn't like it 'cuz this game p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don't recommend this game. I don't care abou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deep describing of native Taiwan culture of 19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Well at the risk of this review getting buried...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's not a political satire nor a boring propa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  recommended\n",
       "0  Chinese people didn't like it 'cuz this game p...            1\n",
       "1  I don't recommend this game. I don't care abou...            0\n",
       "2  Deep describing of native Taiwan culture of 19...            1\n",
       "3  Well at the risk of this review getting buried...            1\n",
       "4  It's not a political satire nor a boring propa...            1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../input/Devotion_Reviews.csv')\n",
    "df_review = df[['text', 'recommended']].copy()\n",
    "df_review['recommended'] = df['recommended'].astype(dtype=np.int64)\n",
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Chinese character\n",
    "printable = set(string.printable)\n",
    "df_review['cleantext'] = df['text'].apply(lambda row: ''.join(filter(lambda x:x in printable,row)))\n",
    "\n",
    "REPLACE = re.compile('[.;:!\\'?,\\\"()\\[\\]]')\n",
    "def pre_process(text):\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    # tags\n",
    "    text = re.sub('&lt;/?.*?&gt;',' &lt;&gt; ',text)\n",
    "    # special characters and digits\n",
    "    text=re.sub('(\\\\d|\\\\W)+',' ',text)\n",
    "    # remove punctuation\n",
    "    #text = re.sub('[.;:!\\'?,\\\"()\\[\\]]', '', text)\n",
    "    #text = [REPLACE.sub('', line) for line in text]\n",
    "    \n",
    "    return text\n",
    "\n",
    "df_review['cleantext'] = df_review['cleantext'].apply(lambda x:pre_process(x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "#english_stop_words = stopwords.words('english')\n",
    "english_stop_words = ENGLISH_STOP_WORDS\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in english_stop_words])\n",
    "        )\n",
    "    return removed_stop_words\n",
    "\n",
    "df_review['cleantext'] = remove_stop_words(df_review['cleantext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This story is purely fictional. Any resemblance to actual individuals or events are coincidental.\\n本故事纯属虚构，如有雷同，纯属虚构\n",
      "story purely fictional resemblance actual individuals events coincidental n\n"
     ]
    }
   ],
   "source": [
    "print(df_review['text'][10])\n",
    "print(df_review['cleantext'][10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "    Stemming\n",
    "    Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def get_stemmed_text(corpus):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "df_review['stemmedtext'] = get_stemmed_text(df_review['cleantext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>recommended</th>\n",
       "      <th>cleantext</th>\n",
       "      <th>stemmedtext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinese people didn't like it 'cuz this game p...</td>\n",
       "      <td>1</td>\n",
       "      <td>chinese people didn t like cuz game practices ...</td>\n",
       "      <td>chines peopl didn t like cuz game practic free...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don't recommend this game. I don't care abou...</td>\n",
       "      <td>0</td>\n",
       "      <td>don t recommend game don t care political hide...</td>\n",
       "      <td>don t recommend game don t care polit hide ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deep describing of native Taiwan culture of 19...</td>\n",
       "      <td>1</td>\n",
       "      <td>deep describing native taiwan culture s atomsp...</td>\n",
       "      <td>deep describ nativ taiwan cultur s atomspher g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Well at the risk of this review getting buried...</td>\n",
       "      <td>1</td>\n",
       "      <td>risk review getting buried review bomb controv...</td>\n",
       "      <td>risk review get buri review bomb controversi s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's not a political satire nor a boring propa...</td>\n",
       "      <td>1</td>\n",
       "      <td>s political satire boring propaganda redcandle...</td>\n",
       "      <td>s polit satir bore propaganda redcandlegam mer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                        ...                                                                stemmedtext\n",
       "0  Chinese people didn't like it 'cuz this game p...                        ...                          chines peopl didn t like cuz game practic free...\n",
       "1  I don't recommend this game. I don't care abou...                        ...                          don t recommend game don t care polit hide ins...\n",
       "2  Deep describing of native Taiwan culture of 19...                        ...                          deep describ nativ taiwan cultur s atomspher g...\n",
       "3  Well at the risk of this review getting buried...                        ...                          risk review get buri review bomb controversi s...\n",
       "4  It's not a political satire nor a boring propa...                        ...                          s polit satir bore propaganda redcandlegam mer...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def get_lemmatized_text(corpus):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "df_review['lemmatext'] = get_lemmatized_text(df_review['stemmedtext'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.7701863354037267\n",
      "Accuracy for C=0.05: 0.8074534161490683\n",
      "Accuracy for C=0.25: 0.8385093167701864\n",
      "Accuracy for C=0.5: 0.8385093167701864\n",
      "Accuracy for C=1: 0.8509316770186336\n",
      "Final Accuracy: 0.9440993788819876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1,2))\n",
    "ngram_vectorizer.fit(df_review['lemmatext'])\n",
    "X = ngram_vectorizer.transform(df_review['lemmatext'])\n",
    "y = df_review['recommended']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print('Accuracy for C=%s: %s' % (c, accuracy_score(y_test, lr.predict(X_test))))\n",
    "    \n",
    "final_ngram = LogisticRegression(C=1)\n",
    "final_ngram.fit(X, y)\n",
    "print('Final Accuracy: %s' % accuracy_score(y_test, final_ngram.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Words\n",
      "('review', 0.8264656210212834)\n",
      "('stori', 0.7886664567798508)\n",
      "('horror', 0.7805708204233848)\n",
      "('great', 0.7245683530987677)\n",
      "('amaz', 0.7241240985033233)\n",
      "('excel', 0.70819295338569)\n",
      "('worth', 0.6476257573556538)\n",
      "('love', 0.6318299719287049)\n",
      "('horror game', 0.6109478085196917)\n",
      "('awesom', 0.6047624164808856)\n",
      "Negative Words\n",
      "('polit', -1.909847954026398)\n",
      "('disgust', -1.1885759098177382)\n",
      "('independ', -0.9020287921591348)\n",
      "('bad', -0.7596159973042264)\n",
      "('element', -0.7113186538282983)\n",
      "('insult', -0.6343253565733883)\n",
      "('refund', -0.6107995496153661)\n",
      "('redcandl', -0.6054410207477393)\n",
      "('lol', -0.5442279839856778)\n",
      "('polit game', -0.5419982844416432)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "     ngram_vectorizer.get_feature_names(), final_ngram.coef_[0])\n",
    "}\n",
    "\n",
    "print('Positive Words')\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True)[:10]:\n",
    "    print(best_positive)\n",
    "    \n",
    "print('Negative Words')\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(),\n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print(best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.7639751552795031\n",
      "Accuracy for C=0.05: 0.7639751552795031\n",
      "Accuracy for C=0.25: 0.7639751552795031\n",
      "Accuracy for C=0.5: 0.7639751552795031\n",
      "Accuracy for C=1: 0.7639751552795031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8214285714285714"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_vectorizer.fit(df_review['lemmatext'])\n",
    "X = tfidf_vectorizer.transform(df_review['lemmatext'])\n",
    "y = df_review['recommended']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print('Accuracy for C=%s: %s' %(c, accuracy_score(y_test, lr.predict(X_test))))\n",
    "    \n",
    "final_tfidf = LogisticRegression(C=1)\n",
    "final_tfidf.fit(X, y)\n",
    "accuracy_score(y, final_tfidf.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Words\n",
      "('stori', 1.1892518051403431)\n",
      "('great', 1.1639163578281155)\n",
      "('horror', 1.1217466143534138)\n",
      "('review', 0.9653257670823109)\n",
      "('horror game', 0.8495859060759398)\n",
      "('atmospher', 0.7613132486208781)\n",
      "('taiwanes', 0.7351852542327205)\n",
      "('amaz', 0.7312840145267567)\n",
      "('play', 0.706856946288395)\n",
      "('excel', 0.6983593822540749)\n",
      "Negative Words\n",
      "('polit', -2.86757270311894)\n",
      "('disgust', -1.453658529178925)\n",
      "('metaphor', -1.1799371920547714)\n",
      "('polit metaphor', -1.0638550712529116)\n",
      "('game polit', -0.9136958953481064)\n",
      "('independ', -0.8961171482741773)\n",
      "('insult', -0.885972911274552)\n",
      "('bad', -0.7206789385921515)\n",
      "('polit game', -0.7161830954859586)\n",
      "('element', -0.7110329739717606)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "     tfidf_vectorizer.get_feature_names(), final_tfidf.coef_[0])\n",
    "}\n",
    "\n",
    "print('Positive Words')\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True)[:10]:\n",
    "    print(best_positive)\n",
    "    \n",
    "print('Negative Words')\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(),\n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print(best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems:\n",
    "\n",
    "1. find the stopwords from nltk library also includes the negative words, like \"didnt'\". The sentence:\"I didn't like the game because...\" becomes \" like game\", which is a bad lead to the result. Therefore, I used stopwords in sklearn library instead. It's better to create own stopwords list to ensure better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'dont like' in feature_to_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04349492386885162"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_to_coef['dont like']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we only consider paired words(2-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6956521739130435\n",
      "Accuracy for C=0.05: 0.6956521739130435\n",
      "Accuracy for C=0.25: 0.6956521739130435\n",
      "Accuracy for C=0.5: 0.6956521739130435\n",
      "Accuracy for C=1: 0.6956521739130435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7857142857142857"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(2,2))\n",
    "tfidf_vectorizer.fit(df_review['lemmatext'])\n",
    "X = tfidf_vectorizer.transform(df_review['lemmatext'])\n",
    "y = df_review['recommended']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print('Accuracy for C=%s: %s' %(c, accuracy_score(y_test, lr.predict(X_test))))\n",
    "    \n",
    "final_tfidf = LogisticRegression(C=1)\n",
    "final_tfidf.fit(X, y)\n",
    "accuracy_score(y, final_tfidf.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Words\n",
      "('horror game', 1.314331181087135)\n",
      "('great game', 0.7780971240659414)\n",
      "('review bomb', 0.7662009030301936)\n",
      "('game great', 0.5350446763491172)\n",
      "('highli recommend', 0.5211051189690845)\n",
      "('winni pooh', 0.492267270586547)\n",
      "('ve play', 0.4439030471822806)\n",
      "('neg review', 0.4420815839101605)\n",
      "('nice game', 0.438237996338948)\n",
      "('play game', 0.4251074451687537)\n",
      "Negative Words\n",
      "('polit metaphor', -1.9481063822950957)\n",
      "('game polit', -1.4166645708629457)\n",
      "('polit game', -1.082228225285144)\n",
      "('independ taiwan', -0.7828908737940444)\n",
      "('taiwan independ', -0.6516963999808965)\n",
      "('metaphor game', -0.6512158178412064)\n",
      "('absolut blind', -0.6355664489344535)\n",
      "('close detent', -0.6355664489344535)\n",
      "('develop disgust', -0.6355664489344535)\n",
      "('hate crap', -0.6355664489344535)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "     tfidf_vectorizer.get_feature_names(), final_tfidf.coef_[0])\n",
    "}\n",
    "\n",
    "print('Positive Words')\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True)[:10]:\n",
    "    print(best_positive)\n",
    "    \n",
    "print('Negative Words')\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(),\n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print(best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less accuracy but can reflect more on why people hate the game, which is the political metaphors hidden in the game. I'll talk more about it in the next article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
