{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "This is a basic LogisticRegression model trained using the data from https://www.kaggle.com/eoveson/convai-datasets-baseline-models\n",
    "\n",
    "The baseline model in that kernal is tuned a little to get the data for this kernal This kernal scored 0.044 in the LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false",
    "_cell_guid": "eb9acbb1-40db-4a60-9c00-7e1134408cb1",
    "_uuid": "7e97dad72af19207237cb816bc898ca5818f4389"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy import sparse\n",
    "# set stopwords\n",
    "\n",
    "# from subprocess import check_output\n",
    "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false",
    "_cell_guid": "bb967e03-d30b-46ec-b9d2-c0f5d4c0ee68",
    "_uuid": "97b399586c43626b73bc77b50e58b952d86ea8da"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false",
    "_cell_guid": "1eebb207-607e-4985-908e-9848888808b1",
    "_uuid": "3e90295dde0dd25158ea9e3464165aa8ea62fd1c"
   },
   "outputs": [],
   "source": [
    "feats_to_concat = ['comment_text']\n",
    "# combining test and train\n",
    "alldata = pd.concat([train[feats_to_concat], test[feats_to_concat]], axis=0)\n",
    "alldata.comment_text.fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false",
    "_cell_guid": "88a8e609-b287-4a7e-b72d-5dcac6f4a55f",
    "_uuid": "741273ee4b5122a37d978708ba29e16879e5b33f"
   },
   "outputs": [],
   "source": [
    "vect_words = TfidfVectorizer(max_features=50000, analyzer='word', ngram_range=(1, 1))\n",
    "vect_chars = TfidfVectorizer(max_features=20000, analyzer='char', ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false",
    "_cell_guid": "6db22032-8e99-4848-8978-be7c68a1e936",
    "_uuid": "cf10b99072cef22bf87ee92c9aa51f035a26e893"
   },
   "outputs": [],
   "source": [
    "all_words = vect_words.fit_transform(alldata.comment_text)\n",
    "all_chars = vect_chars.fit_transform(alldata.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false",
    "_cell_guid": "8f42e0d7-5938-4bb0-beb7-7ddf9f85685d",
    "_uuid": "d074b6b6c5271f462c129c534980c5a0d287599f"
   },
   "outputs": [],
   "source": [
    "train_new = train\n",
    "test_new = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false",
    "_cell_guid": "c068c9bb-bf28-4342-aa71-e575c6d93788",
    "_uuid": "09975f14757c51e19876dab638a39671dfd555e4"
   },
   "outputs": [],
   "source": [
    "train_words = all_words[:len(train_new)]\n",
    "test_words = all_words[len(train_new):]\n",
    "\n",
    "train_chars = all_chars[:len(train_new)]\n",
    "test_chars = all_chars[len(train_new):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false",
    "_cell_guid": "5d55e152-e1cb-4cf0-aa41-e3eec5850b3a",
    "_uuid": "0338f2d0b8f09c751f97afebf1cf8e77d8a10fe3"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['toxic_level', 'attack'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-08c1a736f848>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfeats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'toxic_level'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'attack'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# make sparse matrix with needed data for train and test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_feats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_chars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malldata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeats\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtest_feats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_chars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malldata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeats\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2804\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2806\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1552\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1553\u001b[0m         )\n\u001b[0;32m   1554\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1638\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1639\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1641\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['toxic_level', 'attack'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "feats = ['toxic_level', 'attack']\n",
    "# make sparse matrix with needed data for train and test\n",
    "train_feats = sparse.hstack([train_words, train_chars, alldata[feats][:len(train_new)]])\n",
    "test_feats = sparse.hstack([test_words, test_chars, alldata[feats][len(train_new):]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false",
    "_cell_guid": "350aad79-ee6f-44bc-9d85-4e9652956bd3",
    "_uuid": "da2082c68a367369fac28ddc09eec2e5b6c718bb",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Fit toxic\n",
      "Fitting model\n",
      "Predicting on test\n",
      "===Fit severe_toxic\n",
      "Fitting model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test\n",
      "===Fit obscene\n",
      "Fitting model\n",
      "Predicting on test\n",
      "===Fit threat\n",
      "Fitting model\n",
      "Predicting on test\n",
      "===Fit insult\n",
      "Fitting model\n",
      "Predicting on test\n",
      "===Fit identity_hate\n",
      "Fitting model\n",
      "Predicting on test\n"
     ]
    }
   ],
   "source": [
    "col = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "only_col = ['toxic']\n",
    "\n",
    "preds = np.zeros((test_new.shape[0], len(col)))\n",
    "\n",
    "for i, j in enumerate(col):\n",
    "    print('===Fit '+j)\n",
    "    \n",
    "    model = LogisticRegression(C=4.0, solver='sag')\n",
    "    print('Fitting model')\n",
    "    model.fit(train_feats, train_new[j])\n",
    "      \n",
    "    print('Predicting on test')\n",
    "    preds[:,i] = model.predict_proba(test_feats)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false",
    "_cell_guid": "9d84b909-d93b-4778-b432-701f65a73d3c",
    "_uuid": "3605ca797e6d5e4d05ac2c63d70766c23d2a8cf1",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "subm = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv')\n",
    "\n",
    "submid = pd.DataFrame({'id': subm[\"id\"]})\n",
    "submission = pd.concat([submid, pd.DataFrame(preds, columns = col)], axis=1)\n",
    "submission.to_csv('feat_lr_2cols.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false",
    "_cell_guid": "6d350714-1262-4f91-af11-a7f95750ec84",
    "_uuid": "be385cfe2683246d05dc872d7b09cb4608b73337",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
