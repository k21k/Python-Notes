{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# NATURAL LANGUAGE PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text  cool  useful  \\\n",
       "0      5  My wife took me here on my birthday for breakf...     2       5   \n",
       "1      5  I have no idea why some people give bad review...     0       0   \n",
       "2      4  love the gyro plate. Rice is so good and I als...     0       1   \n",
       "3      5  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...     1       2   \n",
       "4      5  General Manager Scott Petello is a good egg!!!...     0       0   \n",
       "\n",
       "   funny  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk \n",
    "\n",
    "df = pd.read_csv('yelp.csv')\n",
    "df = df[['stars','text', 'cool','useful','funny']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Punctuation, Text Length, Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>text lenght</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>my wife took me here on my birthday for breakf...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>i have no idea why some people give bad review...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. rice is so good and i als...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>rosie, dakota, and i love chaparral dog park!!...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>general manager scott petello is a good egg!!!...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text  cool  useful  \\\n",
       "0      5  my wife took me here on my birthday for breakf...     2       5   \n",
       "1      5  i have no idea why some people give bad review...     0       0   \n",
       "2      4  love the gyro plate. rice is so good and i als...     0       1   \n",
       "3      5  rosie, dakota, and i love chaparral dog park!!...     1       2   \n",
       "4      5  general manager scott petello is a good egg!!!...     0       0   \n",
       "\n",
       "   funny  text lenght  \n",
       "0      0          161  \n",
       "1      0          266  \n",
       "2      0           16  \n",
       "3      0           79  \n",
       "4      0           89  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove punctuation, add a clolumn with text length, , make lower cases\n",
    "\n",
    "df['text'] = df['text'].str.lower() \n",
    "df['text lenght'] = (df['text'].str.split('[\\W_]+'))\n",
    "df['text lenght'] = df['text lenght'].str.len()\n",
    "\n",
    "df.head()\n",
    "\n",
    "# NOTE TO MYSELF\n",
    "# '\\w' is a special character that will match any alphanumeric A-z, a-z, 0-9, along with underscores;\n",
    "# '+' means that the previous character in the regex can appear as many times as we want\n",
    "# This means that '\\w+'' will match arbitrary sequences of alphanumeric characters and underscores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>text lenght</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>my wife took me here on my birthday for breakf...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>['my', 'wife', 'took', 'me', 'here', 'on', 'my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>i have no idea why some people give bad review...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>['i', 'have', 'no', 'idea', 'why', 'some', 'pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. rice is so good and i als...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>['love', 'the', 'gyro', 'plate', 'rice', 'is',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>rosie, dakota, and i love chaparral dog park!!...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>['rosie', 'dakota', 'and', 'i', 'love', 'chapa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>general manager scott petello is a good egg!!!...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>['general', 'manager', 'scott', 'petello', 'is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text  cool  useful  \\\n",
       "0      5  my wife took me here on my birthday for breakf...     2       5   \n",
       "1      5  i have no idea why some people give bad review...     0       0   \n",
       "2      4  love the gyro plate. rice is so good and i als...     0       1   \n",
       "3      5  rosie, dakota, and i love chaparral dog park!!...     1       2   \n",
       "4      5  general manager scott petello is a good egg!!!...     0       0   \n",
       "\n",
       "   funny  text lenght                                         text_split  \n",
       "0      0          161  ['my', 'wife', 'took', 'me', 'here', 'on', 'my...  \n",
       "1      0          266  ['i', 'have', 'no', 'idea', 'why', 'some', 'pe...  \n",
       "2      0           16  ['love', 'the', 'gyro', 'plate', 'rice', 'is',...  \n",
       "3      0           79  ['rosie', 'dakota', 'and', 'i', 'love', 'chapa...  \n",
       "4      0           89  ['general', 'manager', 'scott', 'petello', 'is...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare a column with the text splited (without puntuation), \n",
    "df['text_split'] = (df['text'].str.split('[\\W_]+'))\n",
    "df['text_split'] = df['text_split'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>text lenght</th>\n",
       "      <th>text_split</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>my wife took me here on my birthday for breakf...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>['my', 'wife', 'took', 'me', 'here', 'on', 'my...</td>\n",
       "      <td>[my, wife, took, me, here, on, my, birthday, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>i have no idea why some people give bad review...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>['i', 'have', 'no', 'idea', 'why', 'some', 'pe...</td>\n",
       "      <td>[i, have, no, idea, why, some, people, give, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. rice is so good and i als...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>['love', 'the', 'gyro', 'plate', 'rice', 'is',...</td>\n",
       "      <td>[love, the, gyro, plate, ., rice, is, so, good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>rosie, dakota, and i love chaparral dog park!!...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>['rosie', 'dakota', 'and', 'i', 'love', 'chapa...</td>\n",
       "      <td>[rosie, ,, dakota, ,, and, i, love, chaparral,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>general manager scott petello is a good egg!!!...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>['general', 'manager', 'scott', 'petello', 'is...</td>\n",
       "      <td>[general, manager, scott, petello, is, a, good...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text  cool  useful  \\\n",
       "0      5  my wife took me here on my birthday for breakf...     2       5   \n",
       "1      5  i have no idea why some people give bad review...     0       0   \n",
       "2      4  love the gyro plate. rice is so good and i als...     0       1   \n",
       "3      5  rosie, dakota, and i love chaparral dog park!!...     1       2   \n",
       "4      5  general manager scott petello is a good egg!!!...     0       0   \n",
       "\n",
       "   funny  text lenght                                         text_split  \\\n",
       "0      0          161  ['my', 'wife', 'took', 'me', 'here', 'on', 'my...   \n",
       "1      0          266  ['i', 'have', 'no', 'idea', 'why', 'some', 'pe...   \n",
       "2      0           16  ['love', 'the', 'gyro', 'plate', 'rice', 'is',...   \n",
       "3      0           79  ['rosie', 'dakota', 'and', 'i', 'love', 'chapa...   \n",
       "4      0           89  ['general', 'manager', 'scott', 'petello', 'is...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [my, wife, took, me, here, on, my, birthday, f...  \n",
       "1  [i, have, no, idea, why, some, people, give, b...  \n",
       "2  [love, the, gyro, plate, ., rice, is, so, good...  \n",
       "3  [rosie, ,, dakota, ,, and, i, love, chaparral,...  \n",
       "4  [general, manager, scott, petello, is, a, good...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this does exactly the same as above - but it keeps the punctuation and doe snot have the ''\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df['tokenized'] = df['text'].apply(nltk.word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my',\n",
       " 'wife',\n",
       " 'took',\n",
       " 'me',\n",
       " 'here',\n",
       " 'on',\n",
       " 'my',\n",
       " 'birthday',\n",
       " 'for',\n",
       " 'breakfast',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'excellent',\n",
       " '.',\n",
       " 'the',\n",
       " 'weather',\n",
       " 'was',\n",
       " 'perfect',\n",
       " 'which',\n",
       " 'made',\n",
       " 'sitting',\n",
       " 'outside',\n",
       " 'overlooking',\n",
       " 'their',\n",
       " 'grounds',\n",
       " 'an',\n",
       " 'absolute',\n",
       " 'pleasure',\n",
       " '.',\n",
       " 'our',\n",
       " 'waitress',\n",
       " 'was',\n",
       " 'excellent',\n",
       " 'and',\n",
       " 'our',\n",
       " 'food',\n",
       " 'arrived',\n",
       " 'quickly',\n",
       " 'on',\n",
       " 'the',\n",
       " 'semi-busy',\n",
       " 'saturday',\n",
       " 'morning',\n",
       " '.',\n",
       " 'it',\n",
       " 'looked',\n",
       " 'like',\n",
       " 'the',\n",
       " 'place',\n",
       " 'fills',\n",
       " 'up',\n",
       " 'pretty',\n",
       " 'quickly',\n",
       " 'so',\n",
       " 'the',\n",
       " 'earlier',\n",
       " 'you',\n",
       " 'get',\n",
       " 'here',\n",
       " 'the',\n",
       " 'better',\n",
       " '.',\n",
       " 'do',\n",
       " 'yourself',\n",
       " 'a',\n",
       " 'favor',\n",
       " 'and',\n",
       " 'get',\n",
       " 'their',\n",
       " 'bloody',\n",
       " 'mary',\n",
       " '.',\n",
       " 'it',\n",
       " 'was',\n",
       " 'phenomenal',\n",
       " 'and',\n",
       " 'simply',\n",
       " 'the',\n",
       " 'best',\n",
       " 'i',\n",
       " \"'ve\",\n",
       " 'ever',\n",
       " 'had',\n",
       " '.',\n",
       " 'i',\n",
       " \"'m\",\n",
       " 'pretty',\n",
       " 'sure',\n",
       " 'they',\n",
       " 'only',\n",
       " 'use',\n",
       " 'ingredients',\n",
       " 'from',\n",
       " 'their',\n",
       " 'garden',\n",
       " 'and',\n",
       " 'blend',\n",
       " 'them',\n",
       " 'fresh',\n",
       " 'when',\n",
       " 'you',\n",
       " 'order',\n",
       " 'it',\n",
       " '.',\n",
       " 'it',\n",
       " 'was',\n",
       " 'amazing',\n",
       " '.',\n",
       " 'while',\n",
       " 'everything',\n",
       " 'on',\n",
       " 'the',\n",
       " 'menu',\n",
       " 'looks',\n",
       " 'excellent',\n",
       " ',',\n",
       " 'i',\n",
       " 'had',\n",
       " 'the',\n",
       " 'white',\n",
       " 'truffle',\n",
       " 'scrambled',\n",
       " 'eggs',\n",
       " 'vegetable',\n",
       " 'skillet',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'tasty',\n",
       " 'and',\n",
       " 'delicious',\n",
       " '.',\n",
       " 'it',\n",
       " 'came',\n",
       " 'with',\n",
       " '2',\n",
       " 'pieces',\n",
       " 'of',\n",
       " 'their',\n",
       " 'griddled',\n",
       " 'bread',\n",
       " 'with',\n",
       " 'was',\n",
       " 'amazing',\n",
       " 'and',\n",
       " 'it',\n",
       " 'absolutely',\n",
       " 'made',\n",
       " 'the',\n",
       " 'meal',\n",
       " 'complete',\n",
       " '.',\n",
       " 'it',\n",
       " 'was',\n",
       " 'the',\n",
       " 'best',\n",
       " '``',\n",
       " 'toast',\n",
       " \"''\",\n",
       " 'i',\n",
       " \"'ve\",\n",
       " 'ever',\n",
       " 'had',\n",
       " '.',\n",
       " 'anyway',\n",
       " ',',\n",
       " 'i',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'wait',\n",
       " 'to',\n",
       " 'go',\n",
       " 'back',\n",
       " '!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(df.iloc[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# QUESTION\n",
    "\n",
    "# Does the format difference means something? \n",
    "    # 'text_split ' ['my', 'wife', 'took', 'me', 'here']\n",
    "        - This is a list of strings\n",
    "    # 'tokenized' [my, wife, took, me, here]\n",
    "        - This is a list of strings\n",
    "        \n",
    "        Hence, no difference.\n",
    "\n",
    "\n",
    "# WHy 1/ works and not 2/ (TypeError: expected string or bytes-like object) ?\n",
    "    # 1/ df['tokenized'] = df['text'].apply(nltk.word_tokenize)\n",
    "    # 2/ tk = (nltk.word_tokenize(df['text']))   >> https://pythonhealthcare.org/2018/12/14/101-pre-processing-data-tokenization-stemming-and-removal-of-stop-words/\n",
    "\n",
    "    # 1/ works because when you use .apply(), that method is applied on every single record individually.\n",
    "    # 2/ tk = (nltk.word_tokenize(df['text'])) <-----  This does not work because you are trying to pass a series, while \n",
    "    # it can only consume a string. Modifying it a little bit will work. Have a look at the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'wife', 'took', 'me', 'here', 'on', 'my', 'birthday', 'for', 'breakfast', 'and', 'it', 'was', 'excellent', '.', 'the', 'weather', 'was', 'perfect', 'which', 'made', 'sitting', 'outside', 'overlooking', 'their', 'grounds', 'an', 'absolute', 'pleasure', '.', 'our', 'waitress', 'was', 'excellent', 'and', 'our', 'food', 'arrived', 'quickly', 'on', 'the', 'semi-busy', 'saturday', 'morning', '.', 'it', 'looked', 'like', 'the', 'place', 'fills', 'up', 'pretty', 'quickly', 'so', 'the', 'earlier', 'you', 'get', 'here', 'the', 'better', '.', 'do', 'yourself', 'a', 'favor', 'and', 'get', 'their', 'bloody', 'mary', '.', 'it', 'was', 'phenomenal', 'and', 'simply', 'the', 'best', 'i', \"'ve\", 'ever', 'had', '.', 'i', \"'m\", 'pretty', 'sure', 'they', 'only', 'use', 'ingredients', 'from', 'their', 'garden', 'and', 'blend', 'them', 'fresh', 'when', 'you', 'order', 'it', '.', 'it', 'was', 'amazing', '.', 'while', 'everything', 'on', 'the', 'menu', 'looks', 'excellent', ',', 'i', 'had', 'the', 'white', 'truffle', 'scrambled', 'eggs', 'vegetable', 'skillet', 'and', 'it', 'was', 'tasty', 'and', 'delicious', '.', 'it', 'came', 'with', '2', 'pieces', 'of', 'their', 'griddled', 'bread', 'with', 'was', 'amazing', 'and', 'it', 'absolutely', 'made', 'the', 'meal', 'complete', '.', 'it', 'was', 'the', 'best', '``', 'toast', \"''\", 'i', \"'ve\", 'ever', 'had', '.', 'anyway', ',', 'i', 'ca', \"n't\", 'wait', 'to', 'go', 'back', '!']\n"
     ]
    }
   ],
   "source": [
    "# Putting [0] means I'm taking a string and then passing it inside the method.\n",
    "\n",
    "tk = (nltk.word_tokenize(df['text'][0]))\n",
    "print(tk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Remove Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Simple Example with: NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n",
      "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "print(word_tokens)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Remove Stop Words on df with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>text lenght</th>\n",
       "      <th>text_split</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>cleantext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>my wife took me here on my birthday for breakf...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>['my', 'wife', 'took', 'me', 'here', 'on', 'my...</td>\n",
       "      <td>[my, wife, took, me, here, on, my, birthday, f...</td>\n",
       "      <td>wife took birthday breakfast excellent weather...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>i have no idea why some people give bad review...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>['i', 'have', 'no', 'idea', 'why', 'some', 'pe...</td>\n",
       "      <td>[i, have, no, idea, why, some, people, give, b...</td>\n",
       "      <td>idea people give bad reviews place goes show p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. rice is so good and i als...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>['love', 'the', 'gyro', 'plate', 'rice', 'is',...</td>\n",
       "      <td>[love, the, gyro, plate, ., rice, is, so, good...</td>\n",
       "      <td>love gyro plate rice good also dig candy selec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>rosie, dakota, and i love chaparral dog park!!...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>['rosie', 'dakota', 'and', 'i', 'love', 'chapa...</td>\n",
       "      <td>[rosie, ,, dakota, ,, and, i, love, chaparral,...</td>\n",
       "      <td>rosie dakota love chaparral dog park convenien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>general manager scott petello is a good egg!!!...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>['general', 'manager', 'scott', 'petello', 'is...</td>\n",
       "      <td>[general, manager, scott, petello, is, a, good...</td>\n",
       "      <td>general manager scott petello good egg go deta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text  cool  useful  \\\n",
       "0      5  my wife took me here on my birthday for breakf...     2       5   \n",
       "1      5  i have no idea why some people give bad review...     0       0   \n",
       "2      4  love the gyro plate. rice is so good and i als...     0       1   \n",
       "3      5  rosie, dakota, and i love chaparral dog park!!...     1       2   \n",
       "4      5  general manager scott petello is a good egg!!!...     0       0   \n",
       "\n",
       "   funny  text lenght                                         text_split  \\\n",
       "0      0          161  ['my', 'wife', 'took', 'me', 'here', 'on', 'my...   \n",
       "1      0          266  ['i', 'have', 'no', 'idea', 'why', 'some', 'pe...   \n",
       "2      0           16  ['love', 'the', 'gyro', 'plate', 'rice', 'is',...   \n",
       "3      0           79  ['rosie', 'dakota', 'and', 'i', 'love', 'chapa...   \n",
       "4      0           89  ['general', 'manager', 'scott', 'petello', 'is...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [my, wife, took, me, here, on, my, birthday, f...   \n",
       "1  [i, have, no, idea, why, some, people, give, b...   \n",
       "2  [love, the, gyro, plate, ., rice, is, so, good...   \n",
       "3  [rosie, ,, dakota, ,, and, i, love, chaparral,...   \n",
       "4  [general, manager, scott, petello, is, a, good...   \n",
       "\n",
       "                                           cleantext  \n",
       "0  wife took birthday breakfast excellent weather...  \n",
       "1  idea people give bad reviews place goes show p...  \n",
       "2  love gyro plate rice good also dig candy selec...  \n",
       "3  rosie dakota love chaparral dog park convenien...  \n",
       "4  general manager scott petello good egg go deta...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in stop_words]))\n",
    "    return removed_stop_words\n",
    "\n",
    "df['cleantext'] = df['text'].str.lower()\n",
    "df['cleantext'] = df['cleantext'].str.replace('[\\W_]+',' ')\n",
    "df['cleantext'] = remove_stop_words(df['cleantext'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [wife, took, birthday, breakfast, excellent, ....\n",
       "1       [idea, people, give, bad, reviews, place, ., g...\n",
       "2       [love, gyro, plate, ., rice, good, also, dig, ...\n",
       "3       [rosie, ,, dakota, ,, love, chaparral, dog, pa...\n",
       "4       [general, manager, scott, petello, good, egg, ...\n",
       "                              ...                        \n",
       "9995    [first, visit, ..., lunch, today, -, used, gro...\n",
       "9996    [called, house, deliciousness, !, could, go, i...\n",
       "9997    [recently, visited, olive, ivy, business, last...\n",
       "9998    [nephew, moved, scottsdale, recently, bunch, f...\n",
       "9999    [4-5, locations.., 4.5, star, average.., think...\n",
       "Name: tokenized, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lambda method\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = df['tokenized'].astype(str).tolist()\n",
    "\n",
    "\n",
    "# You can simply do something like this.\n",
    "\n",
    "df['tokenized'].apply(lambda x: [item for item in x if item not in stop_words])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Stemming and Lemmanization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Stemming reduces related words to a common stem.\\\n",
    "It is an optional process step, and it is useful to test accuracy with and without stemming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frighten', 'frighten', 'frighten']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemming = PorterStemmer()\n",
    "my_list = ['frightening', 'frightened', 'frightens']\n",
    "\n",
    "# Using a Python list comprehension method to apply to all words in my_list\n",
    "print ([stemming.stem(word) for word in my_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: player  Stem: player\n",
      "Actual: learning  Stem: learn\n",
      "Actual: a  Stem: a\n",
      "Actual: play  Stem: play\n",
      "Actual: was  Stem: wa\n",
      "Actual: playing  Stem: play\n",
      "Actual: very  Stem: veri\n",
      "Actual: well  Stem: well\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "word_data = \"player learning a play was playing very well\"\n",
    "# First Word tokenization\n",
    "nltk_tokens = nltk.word_tokenize(word_data)\n",
    "#Next find the roots of the word\n",
    "for w in nltk_tokens:\n",
    "       print(\"Actual: %s  Stem: %s\"  % (w,porter_stemmer.stem(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: player  Lemma: player\n",
      "Actual: learning  Lemma: learning\n",
      "Actual: a  Lemma: a\n",
      "Actual: play  Lemma: play\n",
      "Actual: was  Lemma: wa\n",
      "Actual: playing  Lemma: playing\n",
      "Actual: very  Lemma: very\n",
      "Actual: well  Lemma: well\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "word_data = \"player learning a play was playing very well\"\n",
    "nltk_tokens = nltk.word_tokenize(word_data)\n",
    "for w in nltk_tokens:\n",
    "       print(\"Actual: %s  Lemma: %s\"  % (w,wordnet_lemmatizer.lemmatize(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>text lenght</th>\n",
       "      <th>text_split</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>cleantext</th>\n",
       "      <th>stemmedtext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>my wife took me here on my birthday for breakf...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>['my', 'wife', 'took', 'me', 'here', 'on', 'my...</td>\n",
       "      <td>[my, wife, took, me, here, on, my, birthday, f...</td>\n",
       "      <td>wife took birthday breakfast excellent weather...</td>\n",
       "      <td>wife took birthday breakfast excel weather per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>i have no idea why some people give bad review...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>['i', 'have', 'no', 'idea', 'why', 'some', 'pe...</td>\n",
       "      <td>[i, have, no, idea, why, some, people, give, b...</td>\n",
       "      <td>idea people give bad reviews place goes show p...</td>\n",
       "      <td>idea peopl give bad review place goe show plea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. rice is so good and i als...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>['love', 'the', 'gyro', 'plate', 'rice', 'is',...</td>\n",
       "      <td>[love, the, gyro, plate, ., rice, is, so, good...</td>\n",
       "      <td>love gyro plate rice good also dig candy selec...</td>\n",
       "      <td>love gyro plate rice good also dig candi select</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>rosie, dakota, and i love chaparral dog park!!...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>['rosie', 'dakota', 'and', 'i', 'love', 'chapa...</td>\n",
       "      <td>[rosie, ,, dakota, ,, and, i, love, chaparral,...</td>\n",
       "      <td>rosie dakota love chaparral dog park convenien...</td>\n",
       "      <td>rosi dakota love chaparr dog park conveni surr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>general manager scott petello is a good egg!!!...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>['general', 'manager', 'scott', 'petello', 'is...</td>\n",
       "      <td>[general, manager, scott, petello, is, a, good...</td>\n",
       "      <td>general manager scott petello good egg go deta...</td>\n",
       "      <td>gener manag scott petello good egg go detail l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text  cool  useful  \\\n",
       "0      5  my wife took me here on my birthday for breakf...     2       5   \n",
       "1      5  i have no idea why some people give bad review...     0       0   \n",
       "2      4  love the gyro plate. rice is so good and i als...     0       1   \n",
       "3      5  rosie, dakota, and i love chaparral dog park!!...     1       2   \n",
       "4      5  general manager scott petello is a good egg!!!...     0       0   \n",
       "\n",
       "   funny  text lenght                                         text_split  \\\n",
       "0      0          161  ['my', 'wife', 'took', 'me', 'here', 'on', 'my...   \n",
       "1      0          266  ['i', 'have', 'no', 'idea', 'why', 'some', 'pe...   \n",
       "2      0           16  ['love', 'the', 'gyro', 'plate', 'rice', 'is',...   \n",
       "3      0           79  ['rosie', 'dakota', 'and', 'i', 'love', 'chapa...   \n",
       "4      0           89  ['general', 'manager', 'scott', 'petello', 'is...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [my, wife, took, me, here, on, my, birthday, f...   \n",
       "1  [i, have, no, idea, why, some, people, give, b...   \n",
       "2  [love, the, gyro, plate, ., rice, is, so, good...   \n",
       "3  [rosie, ,, dakota, ,, and, i, love, chaparral,...   \n",
       "4  [general, manager, scott, petello, is, a, good...   \n",
       "\n",
       "                                           cleantext  \\\n",
       "0  wife took birthday breakfast excellent weather...   \n",
       "1  idea people give bad reviews place goes show p...   \n",
       "2  love gyro plate rice good also dig candy selec...   \n",
       "3  rosie dakota love chaparral dog park convenien...   \n",
       "4  general manager scott petello good egg go deta...   \n",
       "\n",
       "                                         stemmedtext  \n",
       "0  wife took birthday breakfast excel weather per...  \n",
       "1  idea peopl give bad review place goe show plea...  \n",
       "2    love gyro plate rice good also dig candi select  \n",
       "3  rosi dakota love chaparr dog park conveni surr...  \n",
       "4  gener manag scott petello good egg go detail l...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def get_stemmed_text(corpus):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "df['stemmedtext'] = get_stemmed_text(df['cleantext'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>text lenght</th>\n",
       "      <th>text_split</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>cleantext</th>\n",
       "      <th>stemmedtext</th>\n",
       "      <th>lemmatext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>my wife took me here on my birthday for breakf...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>['my', 'wife', 'took', 'me', 'here', 'on', 'my...</td>\n",
       "      <td>[my, wife, took, me, here, on, my, birthday, f...</td>\n",
       "      <td>wife took birthday breakfast excellent weather...</td>\n",
       "      <td>wife took birthday breakfast excel weather per...</td>\n",
       "      <td>wife took birthday breakfast excellent weather...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>i have no idea why some people give bad review...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>['i', 'have', 'no', 'idea', 'why', 'some', 'pe...</td>\n",
       "      <td>[i, have, no, idea, why, some, people, give, b...</td>\n",
       "      <td>idea people give bad reviews place goes show p...</td>\n",
       "      <td>idea peopl give bad review place goe show plea...</td>\n",
       "      <td>idea people give bad review place go show plea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. rice is so good and i als...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>['love', 'the', 'gyro', 'plate', 'rice', 'is',...</td>\n",
       "      <td>[love, the, gyro, plate, ., rice, is, so, good...</td>\n",
       "      <td>love gyro plate rice good also dig candy selec...</td>\n",
       "      <td>love gyro plate rice good also dig candi select</td>\n",
       "      <td>love gyro plate rice good also dig candy selec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>rosie, dakota, and i love chaparral dog park!!...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>['rosie', 'dakota', 'and', 'i', 'love', 'chapa...</td>\n",
       "      <td>[rosie, ,, dakota, ,, and, i, love, chaparral,...</td>\n",
       "      <td>rosie dakota love chaparral dog park convenien...</td>\n",
       "      <td>rosi dakota love chaparr dog park conveni surr...</td>\n",
       "      <td>rosie dakota love chaparral dog park convenien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>general manager scott petello is a good egg!!!...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>['general', 'manager', 'scott', 'petello', 'is...</td>\n",
       "      <td>[general, manager, scott, petello, is, a, good...</td>\n",
       "      <td>general manager scott petello good egg go deta...</td>\n",
       "      <td>gener manag scott petello good egg go detail l...</td>\n",
       "      <td>general manager scott petello good egg go deta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text  cool  useful  \\\n",
       "0      5  my wife took me here on my birthday for breakf...     2       5   \n",
       "1      5  i have no idea why some people give bad review...     0       0   \n",
       "2      4  love the gyro plate. rice is so good and i als...     0       1   \n",
       "3      5  rosie, dakota, and i love chaparral dog park!!...     1       2   \n",
       "4      5  general manager scott petello is a good egg!!!...     0       0   \n",
       "\n",
       "   funny  text lenght                                         text_split  \\\n",
       "0      0          161  ['my', 'wife', 'took', 'me', 'here', 'on', 'my...   \n",
       "1      0          266  ['i', 'have', 'no', 'idea', 'why', 'some', 'pe...   \n",
       "2      0           16  ['love', 'the', 'gyro', 'plate', 'rice', 'is',...   \n",
       "3      0           79  ['rosie', 'dakota', 'and', 'i', 'love', 'chapa...   \n",
       "4      0           89  ['general', 'manager', 'scott', 'petello', 'is...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [my, wife, took, me, here, on, my, birthday, f...   \n",
       "1  [i, have, no, idea, why, some, people, give, b...   \n",
       "2  [love, the, gyro, plate, ., rice, is, so, good...   \n",
       "3  [rosie, ,, dakota, ,, and, i, love, chaparral,...   \n",
       "4  [general, manager, scott, petello, is, a, good...   \n",
       "\n",
       "                                           cleantext  \\\n",
       "0  wife took birthday breakfast excellent weather...   \n",
       "1  idea people give bad reviews place goes show p...   \n",
       "2  love gyro plate rice good also dig candy selec...   \n",
       "3  rosie dakota love chaparral dog park convenien...   \n",
       "4  general manager scott petello good egg go deta...   \n",
       "\n",
       "                                         stemmedtext  \\\n",
       "0  wife took birthday breakfast excel weather per...   \n",
       "1  idea peopl give bad review place goe show plea...   \n",
       "2    love gyro plate rice good also dig candi select   \n",
       "3  rosi dakota love chaparr dog park conveni surr...   \n",
       "4  gener manag scott petello good egg go detail l...   \n",
       "\n",
       "                                           lemmatext  \n",
       "0  wife took birthday breakfast excellent weather...  \n",
       "1  idea people give bad review place go show plea...  \n",
       "2  love gyro plate rice good also dig candy selec...  \n",
       "3  rosie dakota love chaparral dog park convenien...  \n",
       "4  general manager scott petello good egg go deta...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def get_lemmatized_text(corpus):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "df['lemmatext'] = get_lemmatized_text(df['cleantext'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Word Count: Python style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>place</td>\n",
       "      <td>7397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>food</td>\n",
       "      <td>6357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great</td>\n",
       "      <td>5128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>5109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  freq\n",
       "0  place  7397\n",
       "1   good  6857\n",
       "2   food  6357\n",
       "3  great  5128\n",
       "4   like  5109"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word count, make lower cases at the same time\n",
    "word_count = pd.Series(' '.join(df['lemmatext']).lower().split()).value_counts()\n",
    "word_count = pd.DataFrame(word_count, columns =['freq'])\n",
    "wordcount = word_count.reset_index(inplace=True)\n",
    "word_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Pipeline for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Purpose: use the text in order to derive a predicted rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Methodology:** \n",
    "\n",
    "* a/ <ins>Vectorization</ins>: Count how many times does a word occur in each message (Known as term frequency)\n",
    "\n",
    "* b/ <ins>Term Weighting :</ins> Weigh the counts, so that frequent tokens get lower weight (inverse document frequency)\n",
    "\n",
    "* c / <ins>Normalization:</ins> Normalize the vectors to unit length, to abstract from the original text length (L2 norm)\n",
    "\n",
    "\n",
    "* d/ <ins>Machine Learning</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Implementation:**\n",
    "\n",
    "*  Vectorization is done with a  bag of words object transformed into a dataframe (a sparse matrix)\n",
    "\n",
    "*  Term Weighting and Normalization is done via TF-IDF built in scikit-learns' TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Pipeline 1: simple case**\n",
    "\n",
    "Using a pipeline will streamline the whole process, improve and clarify the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Pipeline Related\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# ML Related\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "yelp = df[(df['stars'] == 1) | (df['stars'] == 5)]\n",
    "yelp\n",
    "\n",
    "X = yelp['lemmatext']\n",
    "y = yelp['stars']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer()),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bow',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('classifier',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 228]\n",
      " [  0 998]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       228\n",
      "           5       0.81      1.00      0.90       998\n",
      "\n",
      "    accuracy                           0.81      1226\n",
      "   macro avg       0.41      0.50      0.45      1226\n",
      "weighted avg       0.66      0.81      0.73      1226\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delchain_default\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Pipeline2 : Iterating through models for model selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Pipeline Related\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "yelp = df[(df['stars'] == 1) | (df['stars'] == 5)]\n",
    "yelp\n",
    "\n",
    "X = yelp['lemmatext']\n",
    "y = yelp['stars']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "                     weights='uniform')\n",
      "model score: 0.814\n",
      "SVC(C=0.025, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      "model score: 0.814\n",
      "NuSVC(break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "      decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "      max_iter=-1, nu=0.5, probability=True, random_state=None, shrinking=True,\n",
      "      tol=0.001, verbose=False)\n",
      "model score: 0.814\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "model score: 0.814\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "model score: 0.814\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=None)\n",
      "model score: 0.814\n",
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "model score: 0.814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    NuSVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier()\n",
    "    ]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    pipe = Pipeline([('bow', CountVectorizer()), \n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('classifier', MultinomialNB()) ])\n",
    "    pipe.fit(X_train, y_train)   \n",
    "    print(classifier)\n",
    "    print(\"model score: %.3f\" % pipe.score(X_test, y_test))  \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Pipeline3 : Implementing GridSearchCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "To cross-validateand select the best parameter configuration at the same time, you can use GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Pipeline Related\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# ML Related\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "yelp = df[(df['stars'] == 1) | (df['stars'] == 5)]\n",
    "yelp\n",
    "\n",
    "\n",
    "X = yelp['lemmatext']\n",
    "y = yelp['stars']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.933916 using {'ML__C': 1.0, 'vect__max_df': 0.8}\n",
      "0.860490 (0.003008) with: {'ML__C': 0.1, 'vect__max_df': 0.8}\n",
      "0.860490 (0.003008) with: {'ML__C': 0.1, 'vect__max_df': 0.9}\n",
      "0.860490 (0.003008) with: {'ML__C': 0.1, 'vect__max_df': 1.0}\n",
      "0.933916 (0.008155) with: {'ML__C': 1.0, 'vect__max_df': 0.8}\n",
      "0.933916 (0.008155) with: {'ML__C': 1.0, 'vect__max_df': 0.9}\n",
      "0.933916 (0.008155) with: {'ML__C': 1.0, 'vect__max_df': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Intake 1\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('ML', LinearSVC()) ])\n",
    "\n",
    "vect__max_df = [0.8,0.9,1.0]\n",
    "ML__C = [0.1,1.0]   \n",
    "\n",
    "param_grid = dict(vect__max_df=vect__max_df, ML__C = ML__C)\n",
    "\n",
    "# do 5-fold cross validation for each of the 6 possible combinations of the parameter values above\n",
    "grid = GridSearchCV(pipeline, cv=5, param_grid = param_grid)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.869580 using {'ML__n_neighbors': 12, 'ML__weights': 'uniform'}\n",
      "0.855245 (0.009976) with: {'ML__n_neighbors': 5, 'ML__weights': 'uniform'}\n",
      "0.855245 (0.009976) with: {'ML__n_neighbors': 5, 'ML__weights': 'distance'}\n",
      "0.860490 (0.013695) with: {'ML__n_neighbors': 6, 'ML__weights': 'uniform'}\n",
      "0.856643 (0.002925) with: {'ML__n_neighbors': 6, 'ML__weights': 'distance'}\n",
      "0.860490 (0.006762) with: {'ML__n_neighbors': 7, 'ML__weights': 'uniform'}\n",
      "0.860490 (0.006762) with: {'ML__n_neighbors': 7, 'ML__weights': 'distance'}\n",
      "0.868531 (0.004870) with: {'ML__n_neighbors': 8, 'ML__weights': 'uniform'}\n",
      "0.860839 (0.003600) with: {'ML__n_neighbors': 8, 'ML__weights': 'distance'}\n",
      "0.862238 (0.005462) with: {'ML__n_neighbors': 9, 'ML__weights': 'uniform'}\n",
      "0.862238 (0.005462) with: {'ML__n_neighbors': 9, 'ML__weights': 'distance'}\n",
      "0.867832 (0.006216) with: {'ML__n_neighbors': 10, 'ML__weights': 'uniform'}\n",
      "0.860490 (0.001308) with: {'ML__n_neighbors': 10, 'ML__weights': 'distance'}\n",
      "0.863636 (0.002925) with: {'ML__n_neighbors': 11, 'ML__weights': 'uniform'}\n",
      "0.863636 (0.002925) with: {'ML__n_neighbors': 11, 'ML__weights': 'distance'}\n",
      "0.869580 (0.007384) with: {'ML__n_neighbors': 12, 'ML__weights': 'uniform'}\n",
      "0.862238 (0.004339) with: {'ML__n_neighbors': 12, 'ML__weights': 'distance'}\n",
      "0.857692 (0.003766) with: {'ML__n_neighbors': 13, 'ML__weights': 'uniform'}\n",
      "0.857692 (0.003766) with: {'ML__n_neighbors': 13, 'ML__weights': 'distance'}\n",
      "0.826573 (0.006671) with: {'ML__n_neighbors': 1, 'ML__weights': 'uniform'}\n",
      "0.826573 (0.006671) with: {'ML__n_neighbors': 1, 'ML__weights': 'distance'}\n",
      "0.848252 (0.012283) with: {'ML__n_neighbors': 4, 'ML__weights': 'uniform'}\n",
      "0.853147 (0.006541) with: {'ML__n_neighbors': 4, 'ML__weights': 'distance'}\n",
      "0.858741 (0.003008) with: {'ML__n_neighbors': 15, 'ML__weights': 'uniform'}\n",
      "0.858741 (0.003008) with: {'ML__n_neighbors': 15, 'ML__weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# Intake 2\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('ML', KNeighborsClassifier()) ])\n",
    "\n",
    "ML__n_neighbors = [5,6,7,8,9,10,11,12,13,1,4,15]   \n",
    "ML__weights = ['uniform', 'distance']\n",
    "\n",
    "KNeighborsClassifier()\n",
    "\n",
    "param_grid = dict(ML__n_neighbors = ML__n_neighbors, ML__weights = ML__weights)\n",
    "\n",
    "# do 5-fold cross validation for each of the 6 possible combinations of the parameter values above\n",
    "grid = GridSearchCV(pipeline, cv=5, param_grid = param_grid)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
